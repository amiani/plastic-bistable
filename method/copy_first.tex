\subsection*{The Copy First Task}

In order to investigate the ability of the PBRC to efficiently memorize high-dimensional patterns over long time horizons, we will test its performance on the copy first task.
Copy first is a temporal prediction task that is an effective test of a model's ability to maintain long term memories. In this task, the model is presented with a sequence of \(T\) inputs drawn from a standard multivariate normal distribution of dimension \(D\). On the last timestep, \(T\), the model's output is recorded with all other outputs being discarded. The final output is then compared to the first input, and a mean squared error loss function is used to measure their distance. The model must therefore learn to remember the first input and output it at the last timestep. Since the model is presented with a new random input at each timestep, it must also learn to ignore all subsequent inputs, and not let them perturb the memory of the first input. When \(T\) is large (i.e. > 5), this task is very difficult for most recurrent models, including the GRU. Vecoven et al.\cite{vecoven2021brc} demonstrated the effectiveness of the BRC and nBRC models relative to various other recurrent models on this task, but only in the one-dimensional case. In this work I compare the nBRC and PBRC models on versions of this task with input dimension greater than one.

All models and experiments were implemented in python using the JAX\cite{jax2018github} and Flax\cite{flax2020github} libraries. Code can be found at \href{https://github.com/amiani/plasticgru}{github.com/amiani/plasticgru}.