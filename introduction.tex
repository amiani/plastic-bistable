\section{Introduction}

The past ten years have seen an explosion in interest in machine learning and artificial intelligence. At the center of this interest are a class of algorithms known as neural networks. Thanks to their dramatic success on a variety of difficult problems, neural networks are now widely used in many different areas of science, engineering and business. Recent work applying neural networks has improved the state of the art in a number of important areas, including computer vision, robot control, game playing, speech recognition and natural language processing. All of these areas boast many examples of temporal prediction problems, where the goal is to predict the future given the past. For example, a computer vision system might be tasked with predicting what object will be visible in the next few seconds, or your phone keyboard might be tasked with predicting what word you will type next. These problems are generally well-studied, and a class of neural networks known as recurrent neural networks (RNNs) have proven to work extremely well in many cases.

A typical neural network model is a fixed, parameterized function of its inputs. Its parameters are changed during training to best fit the training data it is given, but the network cannot adapt to its inputs in any way once training is complete.
On the other hand, a recurrent neural network is a dynamic model. It has a memory of its past that is updated with each input. This is a powerful feature that allows the network to learn to leverage temporal correlations in its inputs. This key feature is what makes recurrent neural networks so effective at temporal prediction and sequential decision making problems.

Various variations on the standard RNN formular are used in practice, including the now-widespread Long-Short Term Memory\cite{hochreiter1997lstm} (LSTM), and most relevantly to this report, the Gated Recurrent Unit\cite{cho2014gru} (GRU). These introduce methods of alleviating the so-called vanishing/exploding gradient problem, which will be explored in more detail in the next section. The LSTM and GRU are in effect much more capable than the basic RNN of learning long-range dependencies. The GRU is of particular interest here, as it is forms the basis for another type of recurrent neural network reviewed in this report, the Bistable Recurrent Cell\cite{vecoven2021brc}.

The Bistable Recurrent Cell is a recently introduced model that seeks to improve on the GRU by appealing to cellular dynamics that are more closely aligned with those found in biological neural networks. Vecoven et al.\cite{vecoven2021brc} showed that the BRC was more effective than the LSTM and GRU at tasks that neccesitate holding onto a particular input for a long period of time, while only requiring two simple tweaks to the equations that govern the updates to the GRU's memory.
This report builds on the results of Vecoven et al.\cite{vecoven2021brc} and introduces a new model, the Plastic Bistable Recurrent Cell. This model is a further variation of the GRU formula, adding plastic connections between elements of the networks's memory. These plastic connections follow the formulation of Miconi et at.\cite{miconi2018diffplas}, roughly implementing Hebb's rule, a theory of how learning happens in the brain. Miconi et al. showed how plastic networks were able to memorize multiple high-dimensional inputs in a short amount of time, and this, combined with the long-term memorization capability of bistable recurrent cells, is the basis for the model presented in this report.