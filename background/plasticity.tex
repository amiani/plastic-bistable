\subsection*{Differentiable Plasticity}

One of the ways biological neural networks are believed to update the connection strengths between neurons is through a process called synaptic plasticity. Plasticity is the ability of a synapse (connection between two neurons) to change its strength based on the activations of the neurons it connects. The most widespread theory of plasticity is called Hebb's rule \cite{hebb1949rule}, which was proposed as an explanation for learning and memory in the brain. Hebb's rule states that neurons that fire together, wire together i.e. that the strength of a synapse is increased when the activation of its presynaptic neuron is (perhaps along with other neurons) the cause of the activation of its postsynaptic neuron. Although many learning rules based on this fundamnetal idea are possible, Miconi et al.\cite{miconi2018diffplas} proposed a plastic learning rule that is differentiable, a desirable property as it allows for the efficient training of neural networks with many parameters. In their formulation, synapses have two weights, one that is static during each episode (i.e. the lifetime of the model), and one that is plastic, being updated based on its pre- and post-synaptic neuron activations. The plastic weight \(H_{i,j}\) between neurons \(i\) and \(j\) is updated at each timestep according to the recursive formula

\[ H_{i,j}(t) = (1-\eta)H_{i,j}(t-1) + \eta x_j(t)x_i(t-1) \] 

Here \(x_i\) and \(x_j\) are the pre- and post-synaptic neuron activations, respectively, and \(\eta\) is a learning rate parameter shared by all synapses that is optimized via gradient descent. When implementing this update rule using a numerical computing library, the pre- and post-synaptic activations will be typically be represented as vectors, so all the products of \(x_i\) and \(x_j\) can be calculated simply as an outer product of the activation vectors.

\[ H(t) = (1-\eta)H(t-1) + \eta \mathbf{x}(t) \otimes \mathbf{x}(t-1) \]

Where \(\otimes\) is the vector outer product. Each synapse's plastic weight is reset to 0 at the beginning of each episode. In this way the plastic weight accumulates the history of neuron activities at either end of the synapse for the lifetime of the model only. Neuron activation are then are calculated using both the static weight \(w_{i,j}\) and plastic weight \(H_{i,j}\), as well as a per-synapse plasticity parameter, \(\alpha_{i,j}\) according to

\[ x_j(t) = \sigma \left( \sum_{i\in inputs} [ w_{i,j}x_i(t-1) + \alpha_{i,j}H_{i,j}(t)x_i(t-1) ] \right) \]

That the plasticity parameter \(\alpha_{i,j}\) is specific to each neuron means that the model is able during training to drive an \(\alpha_{i,j}\) to 0 and therefore recover the standard learning rule for that synapse only. This allows for much flexibility in the model as it can pick exactly where and how much plasticity to use.
